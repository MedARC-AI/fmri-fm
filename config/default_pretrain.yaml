# Name of the run. For output directory and wandb.
name: pretrain_hcp

# Description of the run. Goes in wandb notes.
notes: null

output_dir: checkpoints
seed: 7338
start_epoch: 0

# Path to checkpoint to resume training.
resume: null

# Model
model: mae_vit_base_patch16

# Standard image size of fmri flat datasets.
# Used when creating the model for setting up the patch embedding and such.
img_size: [224, 560]
in_chans: 1

# Mask ratio
# note that the number of visible patches is computed as
#   len_keep = (T // t) * (H // h) * (W // w) * (1 - mask_ratio)
# where (T, H, W) is the clip size and (t, h, w) is the patch size.
#
# so for image size (224, 560) we get the following patches per frame:
#   - 0.75:  122
#   - 0.804: 96
#   - 0.869: 64
#   - 0.9:   48
#   - 0.96:  19
#
# for comparison, original MAE was trained with 0.75 on 224 x 224 (49 patches), while
# MAE-st was trained with 0.9 (19 patches)
mask_ratio: 0.9

# decoder mask ratio for VideoMAEv2 style sparse decoding.
decoder_mask_ratio: null

# Constraints for the visible mask:
#   - tube: patch tube masking, as in VideoMAE
#   - hemi: visible mask constrained to left or right hemisphere
#   - inverse_block: visible bask is a local square block
#   - hemi_inverse_block: visible bask is a square block constrained to one hemi
# Default is unconstrained uniform masking.
masking: null
masking_kwargs:
  # size of the visible block for inverse block masking.
  # note this is intersected with the valid data mask, so not all pixels in the block
  # will ultimately be visible. so should overestimate relative to the desired number of
  # visible patches.
  block_size: 160

# Temporal config.
# t_embed_patch_indices and t_pred_patch_indices define which frames from each patch are
# encoded and decoded respectively. The options are:
#   - null (encode/decode all frames in the patch)
#   - a slice expression like '0:8', '0:None:2'
#   - an explicit list of indices
num_frames: 16
t_patch_size: 16
t_embed_patch_indices: null       # encode all frames
t_pred_patch_indices: "0:None:2"  # decode every other frame

# previous option to specify the temporal patch size of decoder, for backwards
# compatibility.
t_pred_patch_size: 1

decoder_depth: 4
sep_pos_embed: true
cls_embed: true

# initial weight scale for the decoder head. initializing with small scale can help
# avoid the hockey stick loss.
init_decoder_scale: null

# correct for the number of observed pixels in the patch embedding
mask_patch_embed: false

# Optimization
epochs: 100
# batch size per gpu, so total_batch_size = batch_size * num_gpus_per_node * num_nodes
batch_size: 4
accum_iter: 1

# absolute_lr = base_lr * total_batch_size / 256
base_lr: 1e-3
# lower lr bound for cyclic schedulers that hit 0
min_lr: 0.0
warmup_epochs: 5
weight_decay: 0.05
beta: [0.9, 0.95]
clip_grad: 1.0
# disable AMP by setting fp32 to true
fp32: false

# Datasets
datasets:
  train:
    type: flat-wds
    # hcp-flat contains 2000 shards, split into 20 batches of unrelated subjects.
    # train on first 18 batches.
    url: datasets/hcp-flat/hcp-flat_{0000..1799}.tar
    clipping: random
    clipping_kwargs:
      # sample more clips from each series, to saturate the data loader.
      oversample: 4.0
    shuffle: true
    samples_per_epoch: 200000

  val_train:
    # clips from shards {0000..0009} of hcp-flat
    type: flat-clips
    root: datasets/flat-clips/hcp-train-clips-16t
    shuffle: false

  val_hcp:
    # clips from shards {1800..1809} of hcp-flat
    type: flat-clips
    root: datasets/flat-clips/hcp-val-clips-16t
    shuffle: false

  val_nsd:
    # clips from shards {0000..0009} of nsd-flat
    type: flat-clips
    root: datasets/flat-clips/nsd-subj01-clips-16t
    shuffle: false

# Data transform
# clip extreme values to [-vmax, vmax]. note that during flat dataset generation, each
# vertex time series is z-scored for each run. so values should be in normal range.
clip_vmax: 3.0

# normalize each video clip.
#   - global: the clip is globally normalized to mean zero unit variance.
#   - frame: each temporal frame is independently normalized.
# fMRI data have a lot of slow global variation (i.e. the "global signal"). z-scoring
# each clip is one way to try to get the model to focus on more interesting local
# activity variation.
normalize: null

# cropping options
# fixed bbox to crop to (inefficient hack for testing performance on interior crops)
# note, if you set this, you should also update the img_size accordingly
bbox: null
# random resize crop for training only.
random_crop: false
# conservative default settings. scale 0.9 ~= loss of one patch on height and width.
# keep original aspect ratio (560 / 224 = 2.5).
crop_kwargs:
  scale: [0.9, 1.0]
  ratio: [2.5, 2.5]
  interpolation: 3  # PIL interp constant, 2=BILINEAR, 3=BICUBIC

# Data loader
num_workers: 4

checkpoint_period: 5
max_checkpoints: 4

wandb: true
wandb_entity: null
debug: false
device: cuda
